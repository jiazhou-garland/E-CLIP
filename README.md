# E-CLIP: Towards Label-efficient Event-based Open-world Understanding by CLIP

This repository contains the official PyTorch implementation of the paper "E-CLIP: Towards Label-efficient Event-based Open-world Understanding by CLIP" paper.
<div align="center">
<img src="Image/framework.png" width="400px">
</div>

**The codes and checkpoints will be released ASAP after the paper's decision.**

---
# Citation
If you find this paper useful, please consider staring ðŸŒŸ this repo and citing ðŸ“‘ our paper:

```
 @article{zhou2023clip,
  title={E-CLIP: Towards Label-efficient Event-based Open-world Understanding by CLIP},
  author={Zhou, Jiazhou and Zheng, Xu and Lyu, Yuanhuiyi and Wang, Lin},
  journal={arXiv preprint arXiv:2308.03135},
  year={2023}
}
```

---
# Installation
Please refer to [install.md](./docs/install.md) for step-by-step guidance on how to install the packages.

---
# Acknowledgement
We thank the authors of [CLIP](https://github.com/openai/CLIP) for opening source their wonderful works.

---
# License
This repository is released under the [MIT](./LICENSE) License.
